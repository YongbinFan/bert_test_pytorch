{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad824dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef84c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2797e+00, -1.4172e+00, -1.3623e+00,  1.2177e-01,  1.8269e-02,\n",
      "           8.0784e-01, -4.4768e-02, -1.1755e+00, -7.4232e-01, -5.7782e-01],\n",
      "         [ 7.3098e-01,  5.9993e-01,  1.2639e+00, -2.7480e-02,  1.1925e-01,\n",
      "          -1.0514e+00, -1.0568e+00,  3.5277e-01,  1.4204e+00,  1.0459e+00],\n",
      "         [-6.8662e-01,  9.6455e-01, -4.3879e-01,  2.2040e+00,  2.7015e-01,\n",
      "          -9.0225e-04,  1.5371e+00,  1.7592e+00,  1.9147e+00, -1.3205e-01]],\n",
      "\n",
      "        [[-2.2331e-02, -2.2502e-01, -9.1451e-02, -7.1053e-01, -1.1032e+00,\n",
      "           4.4265e-01, -1.2252e+00,  3.5736e-01,  7.1039e-02,  1.3589e-01],\n",
      "         [-2.0371e+00,  1.5617e+00,  1.1252e+00, -8.3916e-01, -6.1203e-01,\n",
      "           2.1617e+00, -1.8118e-01, -8.2919e-01, -4.2711e-01, -2.4156e+00],\n",
      "         [-1.8012e+00, -7.2303e-02, -9.8840e-01,  3.2811e-01, -2.1616e+00,\n",
      "          -6.5104e-01,  1.1123e+00, -4.2092e-01,  7.4069e-01,  5.0277e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# 2 row data like batch size, 3 element , every element is 10 length vector\n",
    "x_input = torch.randn(2,3,10)\n",
    "print(x_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac4922f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim ,  hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        intermediate = self.fc1(inputs)\n",
    "        # activate\n",
    "        intermediate = F.relu(intermediate)\n",
    "        \n",
    "        outputs = self.fc2(intermediate)\n",
    "        \n",
    "        # change to percentage, at the last dimension do the softmax\n",
    "        # this can change to a 5 classification\n",
    "        outputs = F.softmax(outputs, dim =2)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c5009e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 come from x_input\n",
    "# 20 is the hidden layer\n",
    "# 5 will be the output\n",
    "model= MLP(10,20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35848677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1530, 0.2163, 0.2359, 0.2330, 0.1617],\n",
      "         [0.2076, 0.2365, 0.1844, 0.2461, 0.1255],\n",
      "         [0.2799, 0.1869, 0.1767, 0.2100, 0.1464]],\n",
      "\n",
      "        [[0.1773, 0.2275, 0.1987, 0.2372, 0.1593],\n",
      "         [0.0992, 0.2239, 0.2925, 0.2964, 0.0879],\n",
      "         [0.1977, 0.2364, 0.1548, 0.2372, 0.1739]]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "x_output = model(x_input)\n",
    "print(x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8791279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
